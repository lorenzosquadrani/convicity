{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "try_convicity.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPns6VdsMahHRWiHyYCCSVU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzosquadrani/convicity/blob/main/try_convicity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAJA3GzqR4zT"
      },
      "source": [
        "#Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZyDM04jP5ww",
        "outputId": "edf48cd2-cc57-487c-95aa-d42734b02fe9"
      },
      "source": [
        "!git clone https://github.com/lorenzosquadrani/convicity.git\n",
        "!git clone https://github.com/lorenzosquadrani/plasticity.git\n",
        "!mv /content/plasticity/plasticity/__version__.py.in /content/plasticity/plasticity/__version__.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'convicity'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 66 (delta 22), reused 48 (delta 13), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (66/66), done.\n",
            "Checking out files: 100% (14/14), done.\n",
            "Cloning into 'plasticity'...\n",
            "remote: Enumerating objects: 1430, done.\u001b[K\n",
            "remote: Counting objects: 100% (573/573), done.\u001b[K\n",
            "remote: Compressing objects: 100% (369/369), done.\u001b[K\n",
            "remote: Total 1430 (delta 366), reused 376 (delta 202), pack-reused 857\u001b[K\n",
            "Receiving objects: 100% (1430/1430), 59.47 MiB | 21.49 MiB/s, done.\n",
            "Resolving deltas: 100% (911/911), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qoqrag9KRoMl",
        "outputId": "2a16fcb2-3964-4887-ec37-65bf2ae4322f"
      },
      "source": [
        "cd plasticity/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/plasticity\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNfUIIteRqBx"
      },
      "source": [
        "from convicity.cBCM import cBCM\n",
        "\n",
        "from plasticity.model.optimizer import SGD\n",
        "from plasticity.model.weights import Normal\n",
        "from convicity.utils import view_weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXxa3UFVR98I"
      },
      "source": [
        "#Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPeG4OZpz6nh"
      },
      "source": [
        "#load the data\n",
        "trainset = datasets.MNIST('/content/convicity/', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "\n",
        "\n",
        "testset  =  datasets.MNIST('/content/convicity/', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=1000, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaEmJPbQSFly"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbXTtVlYSC52"
      },
      "source": [
        "class LittleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LittleNet, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv_relu_stack = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(24*24, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv_relu_stack(x)\n",
        "        out = self.flatten(x)\n",
        "        out = self.linear_relu_stack(x)\n",
        "        return out"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS8Yl3_YS2ek"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm8hn0kdVUvc"
      },
      "source": [
        "## Training convolutional layer using cBCM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akMozCxxKVo0"
      },
      "source": [
        "X = np.array(trainset.data, dtype = 'float16')/255."
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZV8kA9CVS6G"
      },
      "source": [
        "model = cBCM(\tn_filters = 8, kernel_size = 24,\n",
        "\t\t\t\tnum_epochs=30, batch_size = 100, activation = 'relu',\n",
        "\t\t\t\toptimizer = SGD(lr=4e-2), weights_init = Normal(), interaction_strength = -0.,\n",
        "\t\t\t\trandom_state = 42, verbose = True)\n",
        "\n",
        "model.fit(X[:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY4dorF5XpnK"
      },
      "source": [
        "view_weights(model, rows = 2, cols = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Jm_8jZWNPM"
      },
      "source": [
        "##Training the rest of the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex8wf6xyS13V"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}